# å®¹å™¨åŒ–èˆ‡ç·¨æ’è¦ç¯„ Containerization & Orchestration Standards

## ç›®éŒ„ Table of Contents

1. [Docker å®¹å™¨åŒ–ç­–ç•¥](#docker-å®¹å™¨åŒ–ç­–ç•¥)
2. [å¾®æœå‹™ Docker é…ç½®](#å¾®æœå‹™-docker-é…ç½®)
3. [Docker Compose ç·¨æ’](#docker-compose-ç·¨æ’)
4. [ç’°å¢ƒè®Šæ•¸ç®¡ç†](#ç’°å¢ƒè®Šæ•¸ç®¡ç†)
5. [ç¶²è·¯é…ç½®](#ç¶²è·¯é…ç½®)
6. [è³‡æ–™æŒä¹…åŒ–](#è³‡æ–™æŒä¹…åŒ–)
7. [ç›£æ§èˆ‡æ—¥èªŒ](#ç›£æ§èˆ‡æ—¥èªŒ)
8. [CI/CD æ•´åˆ](#cicd-æ•´åˆ)

## Docker å®¹å™¨åŒ–ç­–ç•¥

### å¾®æœå‹™ Dockerfile ç¯„ä¾‹
```dockerfile
# services/user-service/Dockerfile
FROM python:3.13-slim as builder

WORKDIR /app

# å®‰è£ uv
RUN pip install uv

# è¤‡è£½ä¾è³´æ–‡ä»¶
COPY pyproject.toml uv.lock ./

# å®‰è£ä¾è³´
RUN uv sync --frozen

# ç”Ÿç”¢éšæ®µ
FROM python:3.13-slim as production

WORKDIR /app

# è¤‡è£½å·²å®‰è£çš„ä¾è³´
COPY --from=builder /app/.venv /app/.venv

# è¨­ç½® PATH
ENV PATH="/app/.venv/bin:$PATH"

# è¤‡è£½æ‡‰ç”¨ç¨‹å¼ä»£ç¢¼
COPY ./app ./app

# å»ºç«‹é root ä½¿ç”¨è€…
RUN groupadd -r appuser && useradd -r -g appuser appuser
RUN chown -R appuser:appuser /app
USER appuser

# å¥åº·æª¢æŸ¥
HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
  CMD curl -f http://localhost:8000/health || exit 1

EXPOSE 8000

CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

### å¤šéšæ®µå»ºæ§‹å„ªåŒ–
```dockerfile
# services/order-service/Dockerfile
FROM python:3.13-slim as base

# è¨­å®šåŸºç¤ç’°å¢ƒè®Šæ•¸
ENV PYTHONUNBUFFERED=1 \
    PYTHONDONTWRITEBYTECODE=1 \
    PIP_NO_CACHE_DIR=1 \
    PIP_DISABLE_PIP_VERSION_CHECK=1

# å»ºæ§‹éšæ®µ
FROM base as builder

WORKDIR /app

# å®‰è£ç³»çµ±ä¾è³´
RUN apt-get update && apt-get install -y --no-install-recommends \
    build-essential \
    && rm -rf /var/lib/apt/lists/*

# å®‰è£ uv
RUN pip install uv

# è¤‡è£½ä¸¦å®‰è£ Python ä¾è³´
COPY pyproject.toml uv.lock ./
RUN uv sync --frozen --no-dev

# æ¸¬è©¦éšæ®µ
FROM builder as test

# å®‰è£æ¸¬è©¦ä¾è³´
RUN uv sync --frozen

# è¤‡è£½åŸå§‹ç¢¼
COPY . .

# åŸ·è¡Œæ¸¬è©¦
RUN uv run pytest tests/ --cov=app --cov-report=html

# ç”Ÿç”¢éšæ®µ
FROM base as production

WORKDIR /app

# åªè¤‡è£½ç”Ÿç”¢ä¾è³´
COPY --from=builder /app/.venv /app/.venv

# è¨­ç½® PATH
ENV PATH="/app/.venv/bin:$PATH"

# è¤‡è£½æ‡‰ç”¨ç¨‹å¼
COPY ./app ./app

# å»ºç«‹ä½¿ç”¨è€…
RUN groupadd -r appuser && useradd -r -g appuser appuser \
    && chown -R appuser:appuser /app

USER appuser

EXPOSE 8000

CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

## å¾®æœå‹™ Docker é…ç½®

### .dockerignore é…ç½®
```
# .dockerignore - å¾®æœå‹™é€šç”¨é…ç½®
**/__pycache__
**/*.pyc
**/*.pyo
**/*.pyd
**/*.pytest_cache
**/node_modules
**/coverage
**/htmlcov
**/.git
**/.gitignore
**/README.md
**/Dockerfile
**/docker-compose*.yml
**/.vscode
**/.idea
**/tests/
**/.coverage
**/*.log
**/temp/
**/tmp/
```

### æœå‹™ç‰¹å®š Docker Compose
```yaml
# services/user-service/docker-compose.service.yml
version: '3.8'

services:
  user-service:
    build:
      context: .
      dockerfile: Dockerfile
      target: production
    environment:
      - DATABASE_URL=postgresql+asyncpg://user_service:${USER_DB_PASSWORD}@user-db:5432/user_service_db
      - KAFKA_BOOTSTRAP_SERVERS=kafka:29092
      - REDIS_URL=redis://redis:6379/0
      - LOG_LEVEL=INFO
    depends_on:
      user-db:
        condition: service_healthy
      kafka:
        condition: service_started
    networks:
      - user-network
      - kafka-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 256M

  user-db:
    image: postgres:16-alpine
    environment:
      - POSTGRES_DB=user_service_db
      - POSTGRES_USER=user_service
      - POSTGRES_PASSWORD=${USER_DB_PASSWORD}
    volumes:
      - user_db_data:/var/lib/postgresql/data
      - ./init.sql:/docker-entrypoint-initdb.d/init.sql:ro
    networks:
      - user-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U user_service"]
      interval: 30s
      timeout: 10s
      retries: 5
    deploy:
      resources:
        limits:
          memory: 256M

volumes:
  user_db_data:

networks:
  user-network:
    driver: bridge
  kafka-network:
    external: true
```

## Docker Compose ç·¨æ’

### ä¸»ç·¨æ’æ–‡ä»¶
```yaml
# docker-compose.microservices.yml
version: '3.8'

x-common-variables: &common-variables
  KAFKA_BOOTSTRAP_SERVERS: kafka:29092
  REDIS_URL: redis://redis:6379
  LOG_LEVEL: ${LOG_LEVEL:-INFO}
  ENVIRONMENT: ${ENVIRONMENT:-development}

services:
  # API Gateway
  kong:
    image: kong:3.4-alpine
    environment:
      KONG_DATABASE: "off"
      KONG_DECLARATIVE_CONFIG: /kong/declarative/kong.yml
      KONG_PROXY_ACCESS_LOG: /dev/stdout
      KONG_ADMIN_ACCESS_LOG: /dev/stdout
      KONG_PROXY_ERROR_LOG: /dev/stderr
      KONG_ADMIN_ERROR_LOG: /dev/stderr
      KONG_ADMIN_LISTEN: 0.0.0.0:8001
    volumes:
      - ./infrastructure/kong/kong.yml:/kong/declarative/kong.yml:ro
    ports:
      - "${KONG_PROXY_PORT:-8000}:8000"
      - "${KONG_ADMIN_PORT:-8001}:8001"
    networks:
      - kong-network
    healthcheck:
      test: ["CMD", "kong", "health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # åŸºç¤è¨­æ–½æœå‹™
  zookeeper:
    image: confluentinc/cp-zookeeper:7.4.0
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    volumes:
      - zookeeper_data:/var/lib/zookeeper/data
      - zookeeper_logs:/var/lib/zookeeper/log
    networks:
      - kafka-network

  kafka:
    image: confluentinc/cp-kafka:7.4.0
    depends_on:
      - zookeeper
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092,PLAINTEXT_DOCKER://kafka:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_DOCKER:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT_DOCKER
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    ports:
      - "9092:9092"
    volumes:
      - kafka_data:/var/lib/kafka/data
    networks:
      - kafka-network
    healthcheck:
      test: ["CMD", "kafka-broker-api-versions", "--bootstrap-server", "localhost:9092"]
      interval: 30s
      timeout: 10s
      retries: 3

  redis:
    image: redis:7-alpine
    command: redis-server --appendonly yes
    volumes:
      - redis_data:/data
    networks:
      - redis-network
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3

  # æ¥­å‹™æœå‹™
  user-service:
    build:
      context: ./services/user-service
      dockerfile: Dockerfile
      target: production
    environment:
      <<: *common-variables
      DATABASE_URL: postgresql+asyncpg://user_service:${USER_DB_PASSWORD}@user-db:5432/user_service_db
      SERVICE_NAME: user-service
    depends_on:
      user-db:
        condition: service_healthy
      kafka:
        condition: service_healthy
      redis:
        condition: service_healthy
    networks:
      - user-network
      - kafka-network
      - redis-network
      - kong-network
    deploy:
      replicas: 2
      resources:
        limits:
          cpus: '1.0'
          memory: 1G

  user-db:
    image: postgres:16-alpine
    environment:
      POSTGRES_DB: user_service_db
      POSTGRES_USER: user_service
      POSTGRES_PASSWORD: ${USER_DB_PASSWORD}
    volumes:
      - user_db_data:/var/lib/postgresql/data
    networks:
      - user-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U user_service"]
      interval: 30s
      timeout: 10s
      retries: 5

volumes:
  zookeeper_data:
  zookeeper_logs:
  kafka_data:
  redis_data:
  user_db_data:
  product_db_data:
  order_db_data:

networks:
  kong-network:
    driver: bridge
  kafka-network:
    driver: bridge
  redis-network:
    driver: bridge
  user-network:
    driver: bridge
  product-network:
    driver: bridge
  order-network:
    driver: bridge
```

## ç’°å¢ƒè®Šæ•¸ç®¡ç†

### ç’°å¢ƒé…ç½®æ¨¡æ¿
```bash
# .env.template
# è¤‡è£½æ­¤æ–‡ä»¶ç‚º .env ä¸¦å¡«å…¥å¯¦éš›å€¼

# ç’°å¢ƒè¨­å®š
ENVIRONMENT=development
LOG_LEVEL=INFO

# è³‡æ–™åº«å¯†ç¢¼
USER_DB_PASSWORD=secure_user_password
PRODUCT_DB_PASSWORD=secure_product_password
ORDER_DB_PASSWORD=secure_order_password
PAYMENT_DB_PASSWORD=secure_payment_password

# Kong Gateway
KONG_PROXY_PORT=8000
KONG_ADMIN_PORT=8001

# JWT Secret
JWT_SECRET_KEY=your-super-secret-jwt-key
JWT_ALGORITHM=HS256
JWT_EXPIRE_MINUTES=30

# å¤–éƒ¨æœå‹™
PAYMENT_GATEWAY_URL=https://api.payment-provider.com
NOTIFICATION_SERVICE_API_KEY=your-notification-api-key

# ç›£æ§
JAEGER_AGENT_HOST=jaeger
JAEGER_AGENT_PORT=14268
PROMETHEUS_GATEWAY=prometheus:9091
```

### é–‹ç™¼èˆ‡ç”Ÿç”¢ç’°å¢ƒåˆ†é›¢
```yaml
# docker-compose.override.yml (é–‹ç™¼ç’°å¢ƒ)
version: '3.8'

services:
  user-service:
    environment:
      - DEBUG=true
      - RELOAD=true
    volumes:
      - ./services/user-service:/app:cached
    ports:
      - "8001:8000"
    command: ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000", "--reload"]

  product-service:
    volumes:
      - ./services/product-service:/app:cached
    ports:
      - "8002:8000"
    command: ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000", "--reload"]

  # é–‹ç™¼å·¥å…·
  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    environment:
      KAFKA_CLUSTERS_0_NAME: local
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:29092
    ports:
      - "8080:8080"
    networks:
      - kafka-network

  redis-commander:
    image: rediscommander/redis-commander:latest
    environment:
      REDIS_HOSTS: local:redis:6379
    ports:
      - "8081:8081"
    networks:
      - redis-network
```

```yaml
# docker-compose.prod.yml (ç”Ÿç”¢ç’°å¢ƒ)
version: '3.8'

services:
  user-service:
    environment:
      - DEBUG=false
      - RELOAD=false
    deploy:
      replicas: 3
      resources:
        limits:
          cpus: '2.0'
          memory: 2G
        reservations:
          cpus: '1.0'
          memory: 1G
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"
```

## ç¶²è·¯é…ç½®

### ç¶²è·¯éš”é›¢ç­–ç•¥
```yaml
# networks/networks.yml
version: '3.8'

networks:
  # å‰ç«¯ç¶²è·¯ - å°å¤–æš´éœ²
  frontend-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16

  # API Gateway ç¶²è·¯
  gateway-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.21.0.0/16

  # æ¥­å‹™æœå‹™ç¶²è·¯
  services-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.22.0.0/16

  # è³‡æ–™åº«ç¶²è·¯ - å…§éƒ¨éš”é›¢
  database-network:
    driver: bridge
    internal: true
    ipam:
      config:
        - subnet: 172.23.0.0/16

  # å¿«å–ç¶²è·¯
  cache-network:
    driver: bridge
    internal: true
    ipam:
      config:
        - subnet: 172.24.0.0/16

  # è¨Šæ¯ä½‡åˆ—ç¶²è·¯
  messaging-network:
    driver: bridge
    internal: true
    ipam:
      config:
        - subnet: 172.25.0.0/16
```

## ç›£æ§èˆ‡æ—¥èªŒ

### ç›£æ§å †ç–Šé…ç½®
```yaml
# monitoring/docker-compose.monitoring.yml
version: '3.8'

services:
  prometheus:
    image: prom/prometheus:latest
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus_data:/prometheus
    ports:
      - "9090:9090"
    networks:
      - monitoring

  grafana:
    image: grafana/grafana:latest
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD}
    volumes:
      - grafana_data:/var/lib/grafana
      - ./grafana/provisioning:/etc/grafana/provisioning:ro
    ports:
      - "3000:3000"
    networks:
      - monitoring

  jaeger:
    image: jaegertracing/all-in-one:latest
    environment:
      - COLLECTOR_OTLP_ENABLED=true
    ports:
      - "16686:16686"
      - "14268:14268"
    networks:
      - monitoring

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.11.0
    environment:
      - discovery.type=single-node
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
      - xpack.security.enabled=false
    volumes:
      - elasticsearch_data:/usr/share/elasticsearch/data
    ports:
      - "9200:9200"
    networks:
      - monitoring

  kibana:
    image: docker.elastic.co/kibana/kibana:8.11.0
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
    ports:
      - "5601:5601"
    depends_on:
      - elasticsearch
    networks:
      - monitoring

volumes:
  prometheus_data:
  grafana_data:
  elasticsearch_data:

networks:
  monitoring:
    driver: bridge
```

### æ—¥èªŒé…ç½®
```yaml
# logging/docker-compose.logging.yml
version: '3.8'

x-logging: &default-logging
  driver: "json-file"
  options:
    max-size: "10m"
    max-file: "3"

services:
  user-service:
    logging: *default-logging
    environment:
      - LOG_FORMAT=json
      - LOG_LEVEL=INFO
    labels:
      - "logging=true"
      - "service=user-service"

  # Fluentd æ—¥èªŒæ”¶é›†å™¨
  fluentd:
    image: fluent/fluentd:v1.16-debian-1
    volumes:
      - ./fluentd/fluent.conf:/fluentd/etc/fluent.conf:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
    ports:
      - "24224:24224"
    networks:
      - monitoring
```

## CI/CD æ•´åˆ

### GitLab CI é…ç½®
```yaml
# .gitlab-ci.yml
stages:
  - test
  - build
  - deploy

variables:
  DOCKER_DRIVER: overlay2
  DOCKER_TLS_CERTDIR: "/certs"

# æ¸¬è©¦éšæ®µ
test:microservices:
  stage: test
  image: docker:20.10.16
  services:
    - docker:20.10.16-dind
  script:
    - docker-compose -f docker-compose.test.yml up --build --abort-on-container-exit
    - docker-compose -f docker-compose.test.yml down
  artifacts:
    reports:
      coverage_report:
        coverage_format: cobertura
        path: coverage.xml

# å»ºæ§‹éšæ®µ
build:images:
  stage: build
  image: docker:20.10.16
  services:
    - docker:20.10.16-dind
  before_script:
    - docker login -u $CI_REGISTRY_USER -p $CI_REGISTRY_PASSWORD $CI_REGISTRY
  script:
    - |
      for service in user-service product-service order-service; do
        docker build -t $CI_REGISTRY_IMAGE/$service:$CI_COMMIT_SHA ./services/$service
        docker push $CI_REGISTRY_IMAGE/$service:$CI_COMMIT_SHA
      done
  only:
    - main
    - develop

# éƒ¨ç½²éšæ®µ
deploy:staging:
  stage: deploy
  image: alpine:latest
  before_script:
    - apk add --no-cache openssh-client docker-compose
  script:
    - ssh $DEPLOY_USER@$STAGING_SERVER "
        cd /opt/microservices &&
        export IMAGE_TAG=$CI_COMMIT_SHA &&
        docker-compose -f docker-compose.prod.yml pull &&
        docker-compose -f docker-compose.prod.yml up -d"
  environment:
    name: staging
    url: https://staging.yourdomain.com
  only:
    - develop

deploy:production:
  stage: deploy
  script:
    - ssh $DEPLOY_USER@$PRODUCTION_SERVER "
        cd /opt/microservices &&
        export IMAGE_TAG=$CI_COMMIT_SHA &&
        docker-compose -f docker-compose.prod.yml pull &&
        docker-compose -f docker-compose.prod.yml up -d"
  environment:
    name: production
    url: https://yourdomain.com
  when: manual
  only:
    - main
```

### éƒ¨ç½²è…³æœ¬
```bash
#!/bin/bash
# scripts/deploy.sh

set -e

ENVIRONMENT=${1:-staging}
IMAGE_TAG=${2:-latest}

echo "ğŸš€ Deploying microservices to $ENVIRONMENT..."

# è¨­å®šç’°å¢ƒè®Šæ•¸
export IMAGE_TAG=$IMAGE_TAG
export ENVIRONMENT=$ENVIRONMENT

# æ‹‰å–æœ€æ–°æ˜ åƒ
echo "ğŸ“¥ Pulling latest images..."
docker-compose -f docker-compose.prod.yml pull

# åŸ·è¡Œè³‡æ–™åº«é·ç§»
echo "ğŸ—„ï¸ Running database migrations..."
docker-compose -f docker-compose.prod.yml run --rm user-service uv run alembic upgrade head
docker-compose -f docker-compose.prod.yml run --rm product-service uv run alembic upgrade head
docker-compose -f docker-compose.prod.yml run --rm order-service uv run alembic upgrade head

# éƒ¨ç½²æœå‹™
echo "ğŸ³ Starting services..."
docker-compose -f docker-compose.prod.yml up -d

# ç­‰å¾…æœå‹™å•Ÿå‹•
echo "â³ Waiting for services to be ready..."
./scripts/wait-for-services.sh

# åŸ·è¡Œå¥åº·æª¢æŸ¥
echo "ğŸ¥ Running health checks..."
./scripts/health-check.sh

echo "âœ… Deployment completed successfully!"
```

---

*æœ€å¾Œæ›´æ–°: 2025-01-XX*
