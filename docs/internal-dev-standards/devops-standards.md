# DevOps è¦ç¯„ DevOps Standards

## ç›®éŒ„ Table of Contents

1. [åŸºç¤è¨­æ–½è¦ç¯„](#åŸºç¤è¨­æ–½è¦ç¯„)
2. [å®¹å™¨åŒ–è¦ç¯„](#å®¹å™¨åŒ–è¦ç¯„)
3. [CI/CD æµç¨‹](#cicd-æµç¨‹)
4. [éƒ¨ç½²ç­–ç•¥](#éƒ¨ç½²ç­–ç•¥)
5. [ç›£æ§èˆ‡æ—¥èªŒ](#ç›£æ§èˆ‡æ—¥èªŒ)
6. [å®‰å…¨æ€§è¦ç¯„](#å®‰å…¨æ€§è¦ç¯„)
7. [ç½é›£æ¢å¾©](#ç½é›£æ¢å¾©)

## åŸºç¤è¨­æ–½è¦ç¯„

### æŠ€è¡“æ£§
- **å®¹å™¨å¹³å°**: Docker + Docker Compose
- **åå‘ä»£ç†**: Nginx
- **API Gateway**: Kong (JWT é©—è­‰)
- **ç‰ˆæœ¬æ§åˆ¶**: Git + GitLab
- **CI/CD**: GitLab CI
- **ç›£æ§**: Prometheus + Grafana
- **æ—¥èªŒ**: ELK Stack (Elasticsearch + Logstash + Kibana)

### ç’°å¢ƒé…ç½®

#### ç’°å¢ƒåˆ†å±¤
```yaml
# ç’°å¢ƒå±¤ç´š
environments:
  development:
    description: "æœ¬åœ°é–‹ç™¼ç’°å¢ƒ"
    resources: "æœ€å°è³‡æºé…ç½®"
    data: "æ¨¡æ“¬è³‡æ–™"

  testing:
    description: "æ¸¬è©¦ç’°å¢ƒ"
    resources: "ä¸­ç­‰è³‡æºé…ç½®"
    data: "æ¸¬è©¦è³‡æ–™é›†"

  production:
    description: "ç”Ÿç”¢ç’°å¢ƒ"
    resources: "å®Œæ•´è³‡æºé…ç½®"
    data: "çœŸå¯¦è³‡æ–™"
```

### ç¶²è·¯æ¶æ§‹
```yaml
# ç¶²è·¯é…ç½®
networks:
  frontend_network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16

  backend_network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.21.0.0/16
```

## å®¹å™¨åŒ–è¦ç¯„

### Docker æœ€ä½³å¯¦è¸

#### å¤šéšæ®µæ§‹å»º
```dockerfile
# backend/Dockerfile
FROM python:3.13-slim as builder

WORKDIR /app

# å®‰è£ uv
RUN pip install uv

# è¤‡è£½ä¾è³´æ–‡ä»¶
COPY pyproject.toml uv.lock ./

# å®‰è£ä¾è³´
RUN uv sync --frozen

# ç”Ÿç”¢éšæ®µ
FROM python:3.13-slim as production

WORKDIR /app

# è¤‡è£½å·²å®‰è£çš„ä¾è³´
COPY --from=builder /app/.venv /app/.venv

# è¨­ç½® PATH
ENV PATH="/app/.venv/bin:$PATH"

# è¤‡è£½æ‡‰ç”¨ç¨‹å¼ä»£ç¢¼
COPY . .

# å»ºç«‹é root ä½¿ç”¨è€…
RUN groupadd -r appuser && useradd -r -g appuser appuser
RUN chown -R appuser:appuser /app
USER appuser

# å¥åº·æª¢æŸ¥
HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
  CMD curl -f http://localhost:8000/health || exit 1

EXPOSE 8000

CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

#### å‰ç«¯ Dockerfile
```dockerfile
# frontend/Dockerfile
FROM node:22-alpine as builder

WORKDIR /app

# è¤‡è£½ä¾è³´æ–‡ä»¶
COPY package*.json ./

# å®‰è£ä¾è³´
RUN npm ci --only=production

# è¤‡è£½æºä»£ç¢¼
COPY . .

# æ§‹å»ºæ‡‰ç”¨
RUN npm run build

# ç”Ÿç”¢éšæ®µ
FROM nginx:alpine as production

# è¤‡è£½è‡ªå®šç¾© Nginx é…ç½®
COPY default.conf /etc/nginx/conf.d/default.conf

# è¤‡è£½æ§‹å»ºå¥½çš„éœæ…‹æ–‡ä»¶
COPY --from=builder /app/dist /usr/share/nginx/html

# å»ºç«‹é root ä½¿ç”¨è€…
RUN addgroup -g 1001 -S nginx && \
    adduser -S -D -H -u 1001 -h /var/cache/nginx -s /sbin/nologin -G nginx -g nginx nginx

# å¥åº·æª¢æŸ¥
HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
  CMD curl -f http://localhost:80/health || exit 1

EXPOSE 80

CMD ["nginx", "-g", "daemon off;"]
```

### Docker Compose é…ç½®

#### é–‹ç™¼ç’°å¢ƒ
```yaml
# docker-compose.yml
version: '3.8'

services:
  database:
    image: postgres:16-alpine
    environment:
      POSTGRES_DB: ${POSTGRES_DB:-app_dev}
      POSTGRES_USER: ${POSTGRES_USER:-postgres}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-password}
    volumes:
      - postgres_data:/var/lib/postgresql/data
    networks:
      - backend_network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-postgres}"]
      interval: 30s
      timeout: 10s
      retries: 5

  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
      target: development
    environment:
      DATABASE_URL: postgresql+asyncpg://${POSTGRES_USER:-postgres}:${POSTGRES_PASSWORD:-password}@database:5432/${POSTGRES_DB:-app_dev}
      REDIS_URL: redis://redis:6379
    volumes:
      - ./backend:/app
    depends_on:
      database:
        condition: service_healthy
    networks:
      - backend_network
      - frontend_network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
      target: development
    environment:
      VITE_API_GATEWAY_URL: http://localhost:8000
    volumes:
      - ./frontend:/app
      - /app/node_modules
    depends_on:
      - backend
    networks:
      - frontend_network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5173"]
      interval: 30s
      timeout: 10s
      retries: 3

  redis:
    image: redis:7-alpine
    networks:
      - backend_network
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3

volumes:
  postgres_data:

networks:
  frontend_network:
    driver: bridge
  backend_network:
    driver: bridge
```

#### ç”Ÿç”¢ç’°å¢ƒ
```yaml
# docker-compose.prod.yml
version: '3.8'

services:
  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./nginx/ssl:/etc/nginx/ssl:ro
      - static_files:/usr/share/nginx/html/static
    depends_on:
      - frontend
      - backend
    networks:
      - frontend_network
    restart: unless-stopped

  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
      target: production
    environment:
      VITE_API_GATEWAY_URL: https://api.yourdomain.com
    networks:
      - frontend_network
    restart: unless-stopped

  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
      target: production
    environment:
      DATABASE_URL: ${DATABASE_URL}
      REDIS_URL: ${REDIS_URL}
      SECRET_KEY: ${SECRET_KEY}
    networks:
      - backend_network
      - frontend_network
    restart: unless-stopped

  database:
    image: postgres:16-alpine
    environment:
      POSTGRES_DB: ${POSTGRES_DB}
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./backups:/backups
    networks:
      - backend_network
    restart: unless-stopped

volumes:
  postgres_data:
  static_files:

networks:
  frontend_network:
  backend_network:
```

## CI/CD æµç¨‹

### GitLab CI é…ç½®

#### å®Œæ•´ CI/CD Pipeline
```yaml
# .gitlab-ci.yml
stages:
  - lint
  - test
  - build
  - deploy
  - notify

variables:
  DOCKER_DRIVER: overlay2
  DOCKER_TLS_CERTDIR: "/certs"

# ä»£ç¢¼å“è³ªæª¢æŸ¥
frontend:lint:
  stage: lint
  image: node:22-alpine
  script:
    - cd frontend
    - npm ci
    - npm run lint:check
    - npm run format:check
  only:
    - merge_requests
    - main
  artifacts:
    reports:
      junit: frontend/lint-results.xml

backend:lint:
  stage: lint
  image: python:3.13-slim
  script:
    - cd backend
    - pip install uv
    - uv sync
    - uv run black --check .
    - uv run flake8 . --format=junit-xml --output-file=flake8-results.xml
  only:
    - merge_requests
    - main
  artifacts:
    reports:
      junit: backend/flake8-results.xml

# æ¸¬è©¦éšæ®µ
frontend:test:
  stage: test
  image: node:22-alpine
  script:
    - cd frontend
    - npm ci
    - npm run test:unit
    - npm run test:coverage
  coverage: '/Lines\s*:\s*(\d+\.?\d*)%/'
  artifacts:
    reports:
      coverage_report:
        coverage_format: cobertura
        path: frontend/coverage/cobertura-coverage.xml
      junit: frontend/test-results.xml

backend:test:
  stage: test
  image: python:3.13-slim
  services:
    - postgres:16-alpine
  variables:
    POSTGRES_DB: test_db
    POSTGRES_USER: test_user
    POSTGRES_PASSWORD: test_password
    DATABASE_URL: postgresql+asyncpg://test_user:test_password@postgres:5432/test_db
  script:
    - cd backend
    - pip install uv
    - uv sync
    - uv run pytest --cov=app --cov-report=xml --junit-xml=test-results.xml tests/
  coverage: '/TOTAL.*\s+(\d+%)$/'
  artifacts:
    reports:
      coverage_report:
        coverage_format: cobertura
        path: backend/coverage.xml
      junit: backend/test-results.xml

# æ§‹å»ºéšæ®µ
build:images:
  stage: build
  image: docker:24-dind
  services:
    - docker:24-dind
  before_script:
    - docker login -u $CI_REGISTRY_USER -p $CI_REGISTRY_PASSWORD $CI_REGISTRY
  script:
    - docker build -t $CI_REGISTRY_IMAGE/frontend:$CI_COMMIT_SHA ./frontend
    - docker build -t $CI_REGISTRY_IMAGE/backend:$CI_COMMIT_SHA ./backend
    - docker push $CI_REGISTRY_IMAGE/frontend:$CI_COMMIT_SHA
    - docker push $CI_REGISTRY_IMAGE/backend:$CI_COMMIT_SHA
  only:
    - main
    - develop

# éƒ¨ç½²éšæ®µ
deploy:staging:
  stage: deploy
  image: alpine:latest
  before_script:
    - apk add --no-cache openssh-client
    - eval $(ssh-agent -s)
    - echo "$SSH_PRIVATE_KEY" | tr -d '\r' | ssh-add -
    - mkdir -p ~/.ssh
    - chmod 700 ~/.ssh
    - ssh-keyscan $STAGING_SERVER >> ~/.ssh/known_hosts
    - chmod 644 ~/.ssh/known_hosts
  script:
    - ssh $STAGING_USER@$STAGING_SERVER "
        cd /opt/app &&
        export IMAGE_TAG=$CI_COMMIT_SHA &&
        docker-compose -f docker-compose.staging.yml pull &&
        docker-compose -f docker-compose.staging.yml up -d"
  environment:
    name: staging
    url: https://staging.yourdomain.com
  only:
    - develop

deploy:production:
  stage: deploy
  image: alpine:latest
  before_script:
    - apk add --no-cache openssh-client
    - eval $(ssh-agent -s)
    - echo "$SSH_PRIVATE_KEY" | tr -d '\r' | ssh-add -
  script:
    - ssh $PRODUCTION_USER@$PRODUCTION_SERVER "
        cd /opt/app &&
        export IMAGE_TAG=$CI_COMMIT_SHA &&
        docker-compose -f docker-compose.prod.yml pull &&
        docker-compose -f docker-compose.prod.yml up -d"
  environment:
    name: production
    url: https://yourdomain.com
  when: manual
  only:
    - main

# é€šçŸ¥éšæ®µ
notify:success:
  stage: notify
  image: alpine:latest
  script:
    - apk add --no-cache curl
    - 'curl -X POST -H "Content-type: application/json" --data "{\"text\":\"âœ… Deployment to $CI_ENVIRONMENT_NAME successful: $CI_PIPELINE_URL\"}" $SLACK_WEBHOOK_URL'
  when: on_success

notify:failure:
  stage: notify
  image: alpine:latest
  script:
    - apk add --no-cache curl
    - 'curl -X POST -H "Content-type: application/json" --data "{\"text\":\"âŒ Deployment to $CI_ENVIRONMENT_NAME failed: $CI_PIPELINE_URL\"}" $SLACK_WEBHOOK_URL'
  when: on_failure
```

### éƒ¨ç½²è…³æœ¬

#### é›¶åœæ©Ÿéƒ¨ç½²è…³æœ¬
```bash
#!/bin/bash
# scripts/deploy.sh

set -e

ENVIRONMENT=${1:-staging}
IMAGE_TAG=${2:-latest}

echo "ğŸš€ Starting deployment to $ENVIRONMENT environment..."
echo "ğŸ“¦ Using image tag: $IMAGE_TAG"

# é©—è­‰ç’°å¢ƒ
if [[ ! "$ENVIRONMENT" =~ ^(staging|production)$ ]]; then
    echo "âŒ Invalid environment. Use 'staging' or 'production'"
    exit 1
fi

# è¨­ç½®è®Šæ•¸
COMPOSE_FILE="docker-compose.$ENVIRONMENT.yml"
BACKUP_DIR="/backups/$(date +%Y%m%d_%H%M%S)"

# æª¢æŸ¥å¿…è¦æª”æ¡ˆ
if [ ! -f "$COMPOSE_FILE" ]; then
    echo "âŒ Compose file $COMPOSE_FILE not found"
    exit 1
fi

# å»ºç«‹å‚™ä»½ç›®éŒ„
mkdir -p "$BACKUP_DIR"

# è³‡æ–™åº«å‚™ä»½
echo "ğŸ“‚ Creating database backup..."
docker-compose -f "$COMPOSE_FILE" exec -T database pg_dump -U $POSTGRES_USER $POSTGRES_DB > "$BACKUP_DIR/database.sql"

# æ‹‰å–æ–°æ˜ åƒ
echo "ğŸ“¥ Pulling new images..."
export IMAGE_TAG=$IMAGE_TAG
docker-compose -f "$COMPOSE_FILE" pull

# æ»¾å‹•æ›´æ–°
echo "ğŸ”„ Performing rolling update..."

# æ›´æ–°å¾Œç«¯ (å…ˆæ›´æ–°ä¸€å€‹å¯¦ä¾‹)
docker-compose -f "$COMPOSE_FILE" up -d --no-deps --scale backend=2 backend
sleep 30

# å¥åº·æª¢æŸ¥
echo "ğŸ¥ Performing health check..."
BACKEND_HEALTH=$(curl -s -o /dev/null -w "%{http_code}" http://localhost:8000/health)
if [ "$BACKEND_HEALTH" != "200" ]; then
    echo "âŒ Backend health check failed. Rolling back..."
    docker-compose -f "$COMPOSE_FILE" down
    exit 1
fi

# æ›´æ–°å‰ç«¯
docker-compose -f "$COMPOSE_FILE" up -d --no-deps frontend

# æœ€çµ‚å¥åº·æª¢æŸ¥
sleep 30
FRONTEND_HEALTH=$(curl -s -o /dev/null -w "%{http_code}" http://localhost:80/health)
if [ "$FRONTEND_HEALTH" != "200" ]; then
    echo "âŒ Frontend health check failed. Rolling back..."
    docker-compose -f "$COMPOSE_FILE" down
    exit 1
fi

# æ¸…ç†èˆŠæ˜ åƒ
echo "ğŸ§¹ Cleaning up old images..."
docker image prune -f

echo "âœ… Deployment completed successfully!"
echo "ğŸ“Š Application status:"
docker-compose -f "$COMPOSE_FILE" ps
```

## ç›£æ§èˆ‡æ—¥èªŒ

### Prometheus é…ç½®
```yaml
# monitoring/prometheus/prometheus.yml
global:
  scrape_interval: 15s
  evaluation_interval: 15s

rule_files:
  - "alert_rules.yml"

scrape_configs:
  - job_name: 'prometheus'
    static_configs:
      - targets: ['localhost:9090']

  - job_name: 'backend'
    static_configs:
      - targets: ['backend:8000']
    metrics_path: '/metrics'
    scrape_interval: 10s

  - job_name: 'frontend'
    static_configs:
      - targets: ['frontend:80']
    metrics_path: '/metrics'
    scrape_interval: 30s

  - job_name: 'postgres'
    static_configs:
      - targets: ['postgres-exporter:9187']

alerting:
  alertmanagers:
    - static_configs:
        - targets:
          - alertmanager:9093
```

### å‘Šè­¦è¦å‰‡
```yaml
# monitoring/prometheus/alert_rules.yml
groups:
  - name: application_alerts
    rules:
      - alert: HighErrorRate
        expr: rate(http_requests_total{status=~"5.."}[5m]) > 0.1
        for: 2m
        labels:
          severity: critical
        annotations:
          summary: "High error rate detected"
          description: "Error rate is {{ $value }} errors per second"

      - alert: HighResponseTime
        expr: histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m])) > 1
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High response time detected"
          description: "95th percentile response time is {{ $value }}s"

      - alert: DatabaseDown
        expr: up{job="postgres"} == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "Database is down"
          description: "PostgreSQL database is not responding"
```

### ELK Stack é…ç½®
```yaml
# monitoring/elk/logstash/pipeline/logstash.conf
input {
  beats {
    port => 5044
  }
}

filter {
  if [fields][service] == "backend" {
    grok {
      match => { "message" => "%{TIMESTAMP_ISO8601:timestamp} %{LOGLEVEL:level} %{GREEDYDATA:message}" }
    }

    date {
      match => [ "timestamp", "ISO8601" ]
    }
  }

  if [fields][service] == "frontend" {
    grok {
      match => { "message" => "%{COMBINEDAPACHELOG}" }
    }
  }
}

output {
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "logs-%{[fields][service]}-%{+YYYY.MM.dd}"
  }
}
```

## å®‰å…¨æ€§è¦ç¯„

### SSL/TLS é…ç½®
```nginx
# nginx/ssl.conf
server {
    listen 443 ssl http2;
    server_name yourdomain.com;

    ssl_certificate /etc/nginx/ssl/cert.pem;
    ssl_certificate_key /etc/nginx/ssl/key.pem;

    ssl_protocols TLSv1.2 TLSv1.3;
    ssl_ciphers ECDHE-RSA-AES256-GCM-SHA512:DHE-RSA-AES256-GCM-SHA512;
    ssl_prefer_server_ciphers off;

    add_header Strict-Transport-Security "max-age=63072000" always;
    add_header X-Frame-Options DENY;
    add_header X-Content-Type-Options nosniff;
    add_header X-XSS-Protection "1; mode=block";
}
```

### ç’°å¢ƒè®Šæ•¸ç®¡ç†
```bash
# .env.template
# è³‡æ–™åº«é…ç½®
POSTGRES_DB=your_database
POSTGRES_USER=your_user
POSTGRES_PASSWORD=your_secure_password

# æ‡‰ç”¨ç¨‹å¼é…ç½®
SECRET_KEY=your_secret_key_here
DEBUG=false
ALLOWED_HOSTS=yourdomain.com,www.yourdomain.com

# ç¬¬ä¸‰æ–¹æœå‹™
REDIS_URL=redis://redis:6379
SMTP_HOST=smtp.yourdomain.com
SMTP_PORT=587
```

## ç½é›£æ¢å¾©

### å‚™ä»½ç­–ç•¥
```bash
#!/bin/bash
# scripts/backup.sh

# è³‡æ–™åº«å‚™ä»½
docker-compose exec database pg_dump -U $POSTGRES_USER $POSTGRES_DB | gzip > "backup_$(date +%Y%m%d_%H%M%S).sql.gz"

# æª”æ¡ˆå‚™ä»½
tar -czf "files_backup_$(date +%Y%m%d_%H%M%S).tar.gz" /opt/app/uploads

# ä¸Šå‚³åˆ°é›²ç«¯å„²å­˜
aws s3 cp backup_*.sql.gz s3://your-backup-bucket/database/
aws s3 cp files_backup_*.tar.gz s3://your-backup-bucket/files/

# æ¸…ç†æœ¬åœ°å‚™ä»½ (ä¿ç•™ 7 å¤©)
find . -name "backup_*.sql.gz" -mtime +7 -delete
find . -name "files_backup_*.tar.gz" -mtime +7 -delete
```

### æ¢å¾©ç¨‹åº
```bash
#!/bin/bash
# scripts/restore.sh

BACKUP_FILE=$1

if [ -z "$BACKUP_FILE" ]; then
    echo "Usage: $0 <backup_file>"
    exit 1
fi

# åœæ­¢æ‡‰ç”¨ç¨‹å¼
docker-compose down

# æ¢å¾©è³‡æ–™åº«
gunzip -c "$BACKUP_FILE" | docker-compose exec -T database psql -U $POSTGRES_USER $POSTGRES_DB

# é‡æ–°å•Ÿå‹•æ‡‰ç”¨ç¨‹å¼
docker-compose up -d

echo "âœ… Restore completed successfully!"
```

---

*æœ€å¾Œæ›´æ–°: 2025-01-XX*
